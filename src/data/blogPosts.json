[
  {
    "id": 10,
    "title": "Revolutionizing Intelligence: Convergence of AI and Quantitative Investing",
    "date": "2026-02-01",
    "summary": "The past week has seen significant developments in the field of artificial intelligence, with a Chinese quant shop making strides in open-weight LLMs, and research on neuro-symbolic concepts and creativity. These advancements have far-reaching implications for various industries and our understanding of intelligence. This digest provides an in-depth analysis of the top stories, exploring their technical and practical implications.",
    "content": "## Weekly Overview  The convergence of artificial intelligence and quantitative investing has been a topic of interest in recent years. A Chinese quant shop has been making waves with its development of one of the world's strongest open-weight LLMs. This has sparked discussions about the potential applications of large-scale learning systems in finance and other industries. Additionally, research on neuro-symbolic concepts and creativity has shed light on the capabilities and limitations of AI systems.   #\n\n## The Quant Shop \u2014 AI Lab Convergence  The Chinese quant shop's achievement is significant, as it demonstrates the potential for large-scale learning systems to be applied to complex problems in finance. The shop's LLM is capable of processing vast amounts of data and making predictions with high accuracy. This has implications for the field of quantitative investing, where such systems can be used to analyze market trends and make informed investment decisions. The use of LLMs in finance can also lead to increased efficiency and reduced costs.  The convergence of AI and quantitative investing is driven by the need for more sophisticated analysis and decision-making tools. As the amount of data available in finance continues to grow, the need for systems that can process and analyze this data effectively becomes increasingly important. LLMs, with their ability to learn from large datasets and make accurate predictions, are well-suited to this task.  The development of LLMs by the Chinese quant shop is a significant achievement, with the system demonstrating state-of-the-art performance on a range of benchmarks. The shop's use of a combination of symbolic and connectionist AI techniques has allowed it to create a system that is both powerful and flexible. This has implications for the development of AI systems in other industries, where similar techniques can be applied to complex problems.  **Key Takeaways**:\n\n- The Chinese quant shop has developed one of the world's strongest open-weight LLMs\n- The system is capable of processing vast amounts of data and making accurate predictions\n- The convergence of AI and quantitative investing has the potential to increase efficiency and reduce costs in finance  \n\n**Why It Matters**: The development of LLMs by the Chinese quant shop has significant implications for the field of quantitative investing. The use of such systems can lead to increased efficiency and reduced costs, as well as improved decision-making. The convergence of AI and quantitative investing is a trend that is likely to continue, with significant potential for growth and innovation.\n\n## Building Intelligent Agents with Neuro-Symbolic Concepts  Research on neuro-symbolic concepts has shed light on the capabilities and limitations of AI systems. Neuro-symbolic concepts are a combination of symbolic and connectionist AI techniques, which allow for the creation of systems that are both powerful and flexible. The use of neuro-symbolic concepts in intelligent agents has the potential to enable these agents to learn and reason in a more human-like way.  The development of intelligent agents with neuro-symbolic concepts is a significant area of research, with potential applications in a range of industries. The use of such agents can lead to increased efficiency and improved decision-making, as well as the ability to learn and adapt in complex environments. The research on neuro-symbolic concepts has implications for our understanding of intelligence and the development of more sophisticated AI systems.  The agent acquires a vocabulary of neuro-symbolic concepts for objects, relations, and actions, represented through a combination of symbolic programs and neural networks. These concepts are grounded in sensory inputs and actuation outputs and can be composed to solve novel tasks using general-purpose reasoning and planning algorithms. The use of neuro-symbolic concepts in intelligent agents has the potential to enable these agents to learn and reason in a more human-like way.  **Key Takeaways**:\n\n- Neuro-symbolic concepts are a combination of symbolic and connectionist AI techniques\n- The use of neuro-symbolic concepts in intelligent agents can enable these agents to learn and reason in a more human-like way\n- The development of intelligent agents with neuro-symbolic concepts has potential applications in a range of industries  \n\n**Why It Matters**: The research on neuro-symbolic concepts has significant implications for our understanding of intelligence and the development of more sophisticated AI systems. The use of neuro-symbolic concepts in intelligent agents has the potential to enable these agents to learn and reason in a more human-like way, leading to increased efficiency and improved decision-making.\n\n## Is AI More Creative Than Humans?  A new study has revealed that LLMs are already outperforming the average human in terms of creativity. However, the study also found that the most creative humans are still more creative than AI systems. This has implications for our understanding of creativity and the potential applications of AI systems in creative industries.  The study used a range of benchmarks to evaluate the creativity of LLMs and humans. The results showed that LLMs were capable of generating highly creative and innovative solutions to complex problems. However, the study also found that the most creative humans were still able to outperform AI systems in terms of creativity.  The development of AI systems that are capable of creative thought has significant implications for a range of industries. The use of AI systems in creative industries such as art, music, and writing has the potential to lead to new and innovative forms of creative expression. However, the study also highlights the need for further research into the nature of creativity and the potential limitations of AI systems.  **Key Takeaways**:\n\n- LLMs are already outperforming the average human in terms of creativity\n- The most creative humans are still more creative than AI systems\n- The development of AI systems that are capable of creative thought has significant implications for a range of industries  \n\n**Why It Matters**: The study has significant implications for our understanding of creativity and the potential applications of AI systems in creative industries. The use of AI systems in creative industries has the potential to lead to new and innovative forms of creative expression, but also highlights the need for further research into the nature of creativity and the potential limitations of AI systems.\n\n---\n\n## Seeing the Future  The past week has seen significant developments in the field of artificial intelligence, with a Chinese quant shop making strides in open-weight LLMs, and research on neuro-symbolic concepts and creativity. These advancements have far-reaching implications for various industries and our understanding of intelligence. As AI systems continue to evolve and improve, we can expect to see significant changes in the way we live and work. The convergence of AI and quantitative investing is a trend that is likely to continue, with significant potential for growth and innovation.",
    "tags": [
      "AI",
      "Quantitative Investing",
      "Neuro-Symbolic Concepts",
      "Creativity",
      "LLMs"
    ],
    "sources": [
      {
        "title": "The quant shop \u2014 AI lab convergence",
        "url": "https://www.ft.com/content/18313a5f-ae6e-44e9-a26a-4a81cd3190bf"
      },
      {
        "title": "Building Intelligent Agents with Neuro-Symbolic Concepts",
        "url": "https://cacm.acm.org/research/building-intelligent-agents-with-neuro-symbolic-concepts/"
      },
      {
        "title": "Is AI More Creative Than Humans?",
        "url": "https://www.psychologytoday.com/us/blog/the-future-brain/202602/is-ai-more-creative-than-humans"
      },
      {
        "title": "ArXiv says submissions must be in English: are AI translators up for the job?",
        "url": "https://www.nature.com/articles/d41586-026-00229-0"
      },
      {
        "title": "Top AI Grad Programs to Launch Your Career in Artificial Intelligence",
        "url": "https://www.investopedia.com/top-ai-grad-programs-to-launch-your-career-in-artificial-intelligence-11892224"
      }
    ],
    "link": "https://www.ft.com/content/18313a5f-ae6e-44e9-a26a-4a81cd3190bf"
  },
  {
    "id": 9,
    "title": "AI News: The quant shop \u2014 AI lab convergence",
    "date": "2026-01-27",
    "summary": "This week's highlights include: The quant shop \u2014 AI lab convergence. Stay updated on the latest AI and machine learning developments.",
    "content": "## Overview\n\nThis week brought exciting developments in AI and machine learning.\n\n## Key Developments\n\n#\n\n## The quant shop \u2014 AI lab convergence\n\nWhy is a Chinese quant shop behind one of the world's strongest open-weight LLMs? It turns out that modern quantitative investing and frontier AI labs are converging on the same institutional machine: large-scale learning systems attached to balance sheets.\n\n## Why This Matters\n\nThese developments signal continued rapid progress in AI capabilities.\n\n## Looking Ahead\n\nExpect continued innovation in AI research and applications.",
    "tags": [
      "AI",
      "LLMs",
      "Research"
    ],
    "sources": [
      {
        "title": "The quant shop \u2014 AI lab convergence",
        "url": "https://www.ft.com/content/18313a5f-ae6e-44e9-a26a-4a81cd3190bf"
      },
      {
        "title": "An Introduction To Vertex AI",
        "url": "https://www.unite.ai/an-introduction-to-vertex-ai/"
      },
      {
        "title": "Google, OpenAI, and Anthropic are competing to see whose AI can play Pok\u00e9mon the best \u2014 Twitch streams of beloved RPG game test the models' true might",
        "url": "https://www.msn.com/en-us/technology/artificial-intelligence/google-openai-and-anthropic-are-competing-to-see-whose-ai-can-play-pok\u00e9mon-the-best-twitch-streams-of-beloved-rpg-game-test-the-models-true-might/ar-AA1USZP7"
      }
    ],
    "link": "https://www.ft.com/content/18313a5f-ae6e-44e9-a26a-4a81cd3190bf"
  },
  {
    "id": 8,
    "title": "AI News: AGI? GPUs? Learn the definitions of the most common AI terms to enter our vocabulary",
    "date": "2026-01-19",
    "summary": "This week's highlights include: AGI? GPUs? Learn the definitions of the most common AI terms to enter our vocabulary. Stay updated on the latest AI and machine learning developments.",
    "content": "## Overview\n\nThis week brought exciting developments in AI and machine learning.\n\n## Key Developments\n\n#\n\n## AGI? GPUs? Learn the definitions of the most common AI terms to enter our vocabulary\n\nThe rise of AI has given us an entirely new vocabulary. Here's a list of the top AI terms you need to learn, in alphabetical order.\n\n## Why This Matters\n\nThese developments signal continued rapid progress in AI capabilities.\n\n## Looking Ahead\n\nExpect continued innovation in AI research and applications.",
    "tags": [
      "AI",
      "LLMs",
      "Research"
    ],
    "sources": [
      {
        "title": "AGI? GPUs? Learn the definitions of the most common AI terms to enter our vocabulary",
        "url": "https://www.msn.com/en-us/news/technology/agi-gpus-learn-the-definitions-of-the-most-common-ai-terms-to-enter-our-vocabulary/ar-AA1UruCD"
      },
      {
        "title": "Edge AI: The future of AI inference is smarter local compute",
        "url": "https://www.infoworld.com/article/4117620/edge-ai-the-future-of-ai-inference-is-smarter-local-compute.html"
      },
      {
        "title": "Five top innovative AI research labs worth knowing about in 2026",
        "url": "https://www.msn.com/en-za/technology/artificial-intelligence/five-top-innovative-ai-research-labs-worth-knowing-about-in-2026/ar-AA1UukY1"
      }
    ],
    "link": "https://www.msn.com/en-us/news/technology/agi-gpus-learn-the-definitions-of-the-most-common-ai-terms-to-enter-our-vocabulary/ar-AA1UruCD"
  },
  {
    "id": 7,
    "title": "AI News: Unearthing experimental materials data buried in scientific papers using LLMs",
    "date": "2026-01-13",
    "summary": "This week's highlights include: Unearthing experimental materials data buried in scientific papers using LLMs. Stay updated on the latest AI and machine learning developments.",
    "content": "## Overview\n\nThis week brought exciting developments in AI and machine learning.\n\n## Key Developments\n\n#\n\n## Unearthing experimental materials data buried in scientific papers using LLMs\n\nTechnologies that underpin modern society, such as smartphones and automobiles, rely on a diverse range of functional materials. Materials scientists are therefore working to develop and improve new materials,\n\n## Why This Matters\n\nThese developments signal continued rapid progress in AI capabilities.\n\n## Looking Ahead\n\nExpect continued innovation in AI research and applications.",
    "tags": [
      "AI",
      "LLMs",
      "Research"
    ],
    "sources": [
      {
        "title": "Unearthing experimental materials data buried in scientific papers using LLMs",
        "url": "https://www.msn.com/en-us/news/technology/unearthing-experimental-materials-data-buried-in-scientific-papers-using-llms/ar-AA1TLvOe"
      },
      {
        "title": "Multi-agent, domain-specific and governed models will define healthcare genAI in 2026",
        "url": "https://www.cio.com/article/4114606/multi-agent-domain-specific-and-governed-models-will-define-healthcare-genai-in-2026.html"
      },
      {
        "title": "Global Mofy AI Limited Establishes U.S. Subsidiary Eaglepoint AI, Advancing Global AI Training and Data Engineering Capabilities",
        "url": "https://markets.businessinsider.com/news/stocks/global-mofy-ai-limited-establishes-u-s-subsidiary-eaglepoint-ai-advancing-global-ai-training-and-data-engineering-capabilities-1035682603"
      }
    ],
    "link": "https://www.msn.com/en-us/news/technology/unearthing-experimental-materials-data-buried-in-scientific-papers-using-llms/ar-AA1TLvOe"
  },
  {
    "id": 6,
    "title": "Advancing AI Frontiers: Global Expansion, Technical Breakthroughs, and New Career Paths",
    "date": "2026-01-05",
    "summary": "The AI landscape is rapidly evolving with Global Mofy AI Limited establishing a U.S. subsidiary, significant technical breakthroughs in 2025, and the introduction of new AI and machine learning career paths for Army officers. These developments underscore the growing importance of AI in various sectors. As AI continues to advance, its applications and implications are becoming increasingly diverse and profound.",
    "content": "## Overview\n\nThe field of Artificial Intelligence (AI) has witnessed significant advancements in recent weeks, with developments ranging from global expansions by key players to breakthroughs in AI technology and the introduction of new career paths. These moves not only reflect the growing relevance of AI in the global economy but also highlight its potential to transform various industries. The expansion of AI capabilities is poised to impact everything from content creation to military operations.\n\n## Key Developments\n\n#\n\n## Global Expansion of AI Services\n\u2022 **Global Mofy AI Expansion**: Global Mofy AI Limited has established a U.S. subsidiary named Eaglepoint AI, aiming to enhance its global AI training and data engineering capabilities. This move indicates a strategic push into the U.S. market, leveraging the country's robust technology infrastructure and talent pool.\n\u2022 **Enhanced Capabilities**: The establishment of Eaglepoint AI is expected to bolster Global Mofy's position in the AI-driven technology solutions market, particularly in virtual content production and 3D digital assets development.\n\n#\n\n## Technical Breakthroughs\n\u2022 **DeepSeek-R1 and Ghibli Art**: 2025 has been marked by several groundbreaking research achievements in AI, including the development of DeepSeek-R1 and advancements in Ghibli art, which demonstrate significant leaps in reasoning, multimodality, model efficiency, and AI hardware. These breakthroughs are pivotal for the future of AI, enabling more sophisticated and efficient applications.\n\n#\n\n## Career Path Developments\n\u2022 **Army's AI and Machine Learning Career Path**: The Army has introduced a new career path for officers focusing on AI and machine learning, symbolizing the military's embrace of cutting-edge technology and autonomous warfare. This development underscores the strategic importance of AI in modern military operations and planning.\n\n## Why This Matters\n\nThe recent developments in AI have profound implications for various sectors, from technology and entertainment to defense. The **global expansion of AI services** and **technical breakthroughs** are set to enhance the capabilities of AI systems, making them more integral to business operations, content creation, and military strategy. Furthermore, the introduction of **AI-focused career paths** indicates a recognition of the need for specialized expertise in AI, which will be crucial for the development and ethical deployment of AI technologies.\n\n## Looking Ahead\n\nAs AI continues to evolve, several key areas will be worth watching:\n\n1. **Integration of AI in Mainstream Industries**: How AI is adopted and integrated into various industries will be a critical factor in determining its impact.\n2. **Ethical Considerations and Regulations**: The development of ethical guidelines and regulatory frameworks for AI will be essential to ensure that its benefits are realized while minimizing its risks.\n3. **Talent Development and Acquisition**: The competition for AI talent is expected to intensify, with organizations seeking professionals with expertise in AI and machine learning to drive their innovation and growth strategies.",
    "tags": [
      "GenAI",
      "AI Career Paths",
      "Technical Breakthroughs"
    ],
    "sources": [
      {
        "title": "Global Mofy AI Limited Establishes U.S. Subsidiary Eaglepoint AI",
        "url": "https://www.manilatimes.net/2026/01/05/tmt-newswire/globenewswire/global-mofy-ai-limited-establishes-us-subsidiary-eaglepoint-ai-advancing-global-ai-training-and-data-engineering-capabilities/2252857"
      },
      {
        "title": "ChatGPT Glossary: 61 AI Terms Everyone Should Know",
        "url": "https://www.cnet.com/tech/services-and-software/chatgpt-glossary/"
      },
      {
        "title": "From DeepSeek-R1 to Ghibli art: 5 technical breakthroughs that changed AI in 2025",
        "url": "https://indianexpress.com/article/technology/artificial-intelligence/deepseek-ghibli-art-5-biggest-ai-breakthroughs-2025-10448067/"
      },
      {
        "title": "Army to ring in new year with new AI and machine learning career path for officers",
        "url": "https://www.stripes.com/branches/army/2025-12-31/artificial-intelligence-machine-learning-officer-20257219.html"
      }
    ],
    "link": "https://www.manilatimes.net/2026/01/05/tmt-newswire/globenewswire/global-mofy-ai-limited-establishes-us-subsidiary-eaglepoint-ai-advancing-global-ai-training-and-data-engineering-capabilities/2252857"
  },
  {
    "id": 3,
    "title": "AI Breakthroughs: GPT-5, Llama 3.2, and AlphaFold 3 Revolutionize the Field",
    "date": "2025-12-27",
    "summary": "This week, OpenAI, Meta, and Google DeepMind unveiled significant advancements in AI, including GPT-5, Llama 3.2, and AlphaFold 3, which demonstrate substantial improvements in reasoning, multimodal capabilities, and protein structure prediction. These developments have far-reaching implications for various industries and research fields. The releases showcase the rapid progress being made in AI research and development.",
    "content": "## Overview\n\nThis week has marked a pivotal moment in artificial intelligence with major announcements from three industry giants: OpenAI, Meta, and Google DeepMind. The simultaneous unveiling of GPT-5, Llama 3.2, and AlphaFold 3 signals a new era of capability in reasoning, multimodal processing, and scientific discovery.\n\n## Key Releases\n\n#\n\n## OpenAI GPT-5\nOpenAI's latest frontier model, GPT-5, pushes the boundaries of reasoning and reliability. Early benchmarks suggest:\n\n\u2022 **Enhanced Reasoning**: Significant improvements in complex problem-solving and multi-step logic.\n\u2022 **Personalization**: Deeper ability to adapt to user context and preferences over long conversations.\n\n#\n\n## Meta Llama 3.2\nMeta continues to lead in open weights with Llama 3.2, focusing on efficiency and multimodal integration:\n\n\u2022 **Vision Capabilities**: Native support for image understanding and analysis.\n\u2022 **Edge Performance**: Optimized variants designed to run locally on mobile leverage NPU acceleration.\n\n#\n\n## Google DeepMind AlphaFold 3\nDeepMind's AlphaFold 3 extends its revolutionary protein structure prediction to a broader range of biomolecules:\n\n\u2022 **Broad Applicability**: Can now model DNA, RNA, and ligand interactions with high accuracy.\n\u2022 **Drug Discovery**: Accelerates the pipeline for identifying potential therapeutic targets.\n\n## Implications\n\nThese advancements collectively demonstrate that the pace of AI innovation is accelerating. From foundational reasoning models to specialized scientific tools, the impact of these technologies will be felt across healthcare, software engineering, and creative industries in the coming months.",
    "tags": [
      "GenAI",
      "ProteinStructurePrediction",
      "MultimodalLearning"
    ],
    "link": "https://example.com/gpt5"
  },
  {
    "id": 1,
    "title": "The Rise of Small Language Models",
    "date": "2025-12-23",
    "summary": "Recent weeks have seen a surge in efficient, smaller language models like Phi-2 and Gemini Nano, challenging the notion that bigger is always better.",
    "content": "## Overview\n\nThe AI landscape is witnessing a significant paradigm shift. For years, the prevailing wisdom was clear: bigger models meant better performance. However, recent developments are challenging this assumption in meaningful ways.\n\n## Key Developments\n\n#\n\n## Microsoft Phi-2\nWith just 2.7 billion parameters, Phi-2 has demonstrated performance that rivals models 25 times its size on complex reasoning tasks. This achievement stems from:\n\n\u2022 **Curated Training Data**: High-quality, textbook-style data rather than raw web scrapes\n\u2022 **Novel Architecture**: Efficient attention mechanisms that reduce computational overhead\n\u2022 **Knowledge Distillation**: Learning from larger teacher models\n\n#\n\n## Google Gemini Nano\nDesigned for on-device applications, Gemini Nano runs entirely on mobile processors without cloud connectivity. Key benefits include:\n\n\u2022 **Privacy Preservation**: Data never leaves the device\n\u2022 **Reduced Latency**: No network round-trips required\n\u2022 **Offline Capability**: Works without internet connection\n\n## Why This Matters\n\nThe shift toward smaller, efficient models has profound implications:\n\n1. **Democratization of AI**: Powerful models can now run on consumer hardware\n2. **Environmental Impact**: Reduced energy consumption per inference\n3. **Edge Computing**: Enables AI in IoT devices, cars, and mobile phones\n4. **Cost Reduction**: Lower cloud compute costs for businesses\n\n## Looking Ahead\n\nThis trend suggests the future of AI isn't just about scaling up\u2014it's about doing more with less. Expect to see continued innovation in model compression, quantization, and efficient architectures throughout 2025.",
    "tags": [
      "GenAI",
      "LLMs"
    ],
    "sources": [
      {
        "title": "Phi-2: The surprising power of small language models - Microsoft Research",
        "url": "https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/"
      },
      {
        "title": "Introducing Gemini: Google's Most Capable AI Model",
        "url": "https://blog.google/technology/ai/google-gemini-ai/"
      },
      {
        "title": "The Efficiency Era: How Small Models Are Beating Giants",
        "url": "https://arxiv.org/abs/2312.11420"
      }
    ],
    "link": "https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/"
  },
  {
    "id": 2,
    "title": "Graph Neural Networks in Logistics",
    "date": "2025-12-16",
    "summary": "How GNNs are transforming supply chain optimization by modeling complex relationships between entities in shipping networks.",
    "content": "## Overview\n\nGraph Neural Networks (GNNs) are revolutionizing logistics and supply chain optimization. Unlike traditional models that treat data points independently, GNNs naturally capture the interconnected relationships inherent in shipping networks.\n\n## Real-World Applications\n\n#\n\n## Route Optimization\nGNNs process entire transportation networks simultaneously, considering:\n\n\u2022 **Dynamic Traffic Patterns**: Real-time congestion data\n\u2022 **Weather Conditions**: Impact on delivery times and safety\n\u2022 **Capacity Constraints**: Vehicle and warehouse limitations\n\u2022 **Multi-stop Planning**: Optimizing sequences across dozens of stops\n\n#\n\n## Demand Forecasting\nBy modeling relationships between locations as a graph, GNNs capture:\n\n\u2022 **Spatial Dependencies**: How demand in one area affects nearby regions\n\u2022 **Supplier-Retailer Relationships**: Upstream supply constraints\n\u2022 **Seasonal Patterns**: Geographic variations in demand cycles\n\n#\n\n## Fleet Management\nMajor companies are achieving significant results:\n\n\u2022 **Amazon**: 15% reduction in empty miles through GNN-based truck assignment\n\u2022 **UPS**: Improved package routing efficiency by 12%\n\u2022 **FedEx**: Real-time network reoptimization during disruptions\n\n## Technical Deep Dive\n\nGNNs work by:\n\n1. **Message Passing**: Each node aggregates information from neighbors\n2. **Iterative Updates**: Multiple rounds of message passing capture long-range dependencies\n3. **Prediction**: Final node/edge representations used for optimization decisions\n\n## Future Directions\n\nThe combination of GNNs with reinforcement learning is particularly promising. These hybrid systems can:\n\n\u2022 Learn optimal policies through simulation\n\u2022 Adapt to changing network conditions\n\u2022 Handle uncertainty in demand and supply\n\nExpect significant adoption across logistics, telecommunications, and urban planning in the coming year.",
    "tags": [
      "Optimization",
      "Graph Learning"
    ],
    "sources": [
      {
        "title": "Graph Neural Networks for Combinatorial Optimization - arXiv",
        "url": "https://arxiv.org/abs/2110.09563"
      },
      {
        "title": "How Amazon Uses AI in Its Operations",
        "url": "https://www.aboutamazon.com/news/operations/how-amazon-uses-ai-in-its-operations"
      },
      {
        "title": "DeepMind's Vehicle Routing with Graph Networks",
        "url": "https://www.deepmind.com/research/publications/learning-to-solve-vehicle-routing-problems-with-graph-neural-networks"
      }
    ],
    "link": "https://arxiv.org/abs/2110.09563"
  }
]